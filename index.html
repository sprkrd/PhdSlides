<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>New Methods for Bridging Symbolic-Geometric Reasoning, Addressing Uncertainty and Action Learning in Task Planning for Robotics</title>

    <!--<link rel="stylesheet" href="reveal.js/dist/reset.css">-->
    <!--<link rel="stylesheet" href="reveal.js/dist/reveal.css">-->
    <!--<link rel="stylesheet" href="reveal.js/dist/theme/white.css" id="theme">-->

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reset.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/theme/white.min.css">

    <!-- Theme used for syntax highlighted code -->
    <!--<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">-->

    <link rel="stylesheet" href="css/custom-style.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section class="front-page" data-state="front-page-state">
          <h3>Ph.D. Dissertation</h3>
          <h1>New Methods for Bridging Symbolic-Geometric Reasoning, Addressing Uncertainty and Action Learning in Task Planning for Robotics</h1>

          <hr/>

          <ul class="authors">
            <li>
              <div class="author">
                <span class="name">Alejandro Suárez Hernández</span>
                <span class="email">asuarez@iri.upc.edu</span>
              </div>
            </li>
          </ul>

          <p>Advisors:</p>

          <ul class="authors">
              <li>
                  <div class="author">
                      <span class="name">Carme Torras Genís<sup></sup></span>
                    <span class="email">torras@iri.upc.edu</span>
                  </div>
              </li>
              <li>
                  <div class="author">
                      <span class="name">Guillem Alenyà Ribas<sup></sup></span>
                    <span class="email">galenya@iri.upc.edu</span>
                  </div>
              </li>
          </ul>

          <!--<ol class="affiliations">-->
            <!--<li>Institut de Robòtica i Informàtica Industrial, CSIC-UPC</li>-->
          <!--</ol>-->

          <div class="conference">
            <p class="date">July 25th, 2024</p>
          </div>

          <div class="spaced-horizontally">
              <img src="assets/logos/IRI_logo.svg" height="50px"/>
              <img src="assets/logos/UPC_logo.svg" height="50px"/>
          </div>

          <aside class="notes">

              The title promises three kind of advances: closer coordination
              between task and motion planning, handling uncertainty and
              learning action operators. This is all in hopes of
              making AI planning more widespread in robotics to enjoy its
              advantages. Let's see what those advantages are.

          </aside>

        </section>


        <section>

            <h2 class="numbered-section">Motivation</h2>

            <div class="r-stack">
                <img class="r-stretch" src="img/motivation/frame1.svg">
                <img class="r-stretch fragment" src="img/motivation/frame2.svg">
                <img class="r-stretch fragment" src="img/motivation/frame3.svg">
                <img class="r-stretch fragment" src="img/motivation/frame4.svg">
                <img class="r-stretch fragment" src="img/motivation/frame5.svg">
                <img class="r-stretch fragment" src="img/motivation/frame6.svg">
                <img class="r-stretch fragment" src="img/motivation/frame7.svg">
                <img class="r-stretch fragment" src="img/motivation/frame8.svg">
                <img class="r-stretch fragment" src="img/motivation/frame9.svg">
                <img class="r-stretch fragment" src="img/motivation/frame10.svg">
                <img class="r-stretch fragment" src="img/motivation/frame11.svg">
                <img class="r-stretch fragment" src="img/motivation/frame12.svg">
                <img class="r-stretch fragment" src="img/motivation/frame13.svg">
                <img class="r-stretch fragment" src="img/motivation/frame14.svg">
            </div>


          <aside class="notes">

              There're many desirable qualities in robotics: robustness,
              adaptiveness and explainability are a few. Some of them can be
              more easily achieved than others depending on how we choose to
              implement the solution.

              Let's imagine a spectrum of techniques, with step-by-step
              algorithms at the left hand side, and fully learning approaches
              like RL at the right hand side.

              Now, fully scripted behaviors have some advantages. They can be
              very robust and they are certainly predictable. However,
              we may code in underperforming assumptions about the task,
              the implementation is very time-consuming for the human operator,
              and the
              solutions cannot adapt to new tasks not seen before by the robot.

              A few examples of this are assembly lines, tele-operated drones
              and surgical robots.

              Now let's jump to the other end of the spectrum. Now, making
              a robot learn a task can be less time-consuming for the operator,
              and now the robot can adapt more easily to new tasks. However,
              the robot might not be robust, or at the very least robustness
              cannot be guaranteed on account of the lack of explainability.

              RL has been used to approach fast-paced tasks such as air hockey.
              We also have the example of AlphaGo beating the leading human
              go player. Finally I'll mention quadruped robots that learn
              or refine their locomotion.

              In the middle of all this we find task planning, which sort of
              combines the benefits from these two ends. However, robotics
              presents a unique set of obstacles that make the application of
              task planning much more challenging than virtual environments.

              A few examples of task planning: videogame AI, web service
              composition, and for the sake of giving an embodied agent as an
              example: the Hubble telescope, which uses task planning for
              scheduling observations.

              Our motivation is to address some of the challenges that
              task planning has to overcome in order to be  more appealing for
              roboticists.


          </aside>

        </section>

        <section>
            <h2 class="numbered-section">Objectives</h2>
            <div class="r-stack">
                <img class="r-stretch" src="img/objectives/frame1.svg">
                <img style="z-index:1;position:fixed;top:180px;left:578px" src="img/objectives/lever_example.gif">
                <img style="z-index:1;position:fixed;top:398px;left:275px" class="fragment" src="img/objectives/successful-lever.gif" data-fragment-index="1">
                <img style="z-index:1;position:fixed;top:524px;left:275px" class="fragment" src="img/objectives/unsuccessful-lever.gif" data-fragment-index="1">
                <img class="r-stretch fragment" src="img/objectives/frame2.svg" data-fragment-index="1">
                <img class="r-stretch fragment" src="img/objectives/frame3.svg">
                <img class="r-stretch fragment" src="img/objectives/frame4.svg">
            </div>

            <aside class="notes">
                What are our objectives, specifically? Well, first of all, there
                is a gap between symbolic and geometric reasoning that needs to
                be addressed. This gap is usually not a problem in virtual
                applications, but in robotics we have to take into consideration
                that, at the end of the day, actions have to be executed in the
                real world, and the planning of trajectories seldom is independent
                from the abstract set of actions.

                Secondly, more often than not actions may have unintended effects.
                We would like to anticipate them. This includes avoiding
                risking actions or recovering from them.

                Another form of uncertainty that we want to address is that that
                comes from partial observability. Many times, the limitations
                of the sensors don't allow the robot to have all the relevant
                information about the world.

                We must take into account that, in order for task planning to be
                an opriton at all. Therefore, the final objective is to endow
                robots with the ability to
                learn new skills with the least amount of effort from the operator,
                and as naturally as possible.
            </aside>
        </section>

        <section>
            <h2 class="numbered-section">Contributions</h2>

            <div class="r-stack">
                <img class="r-stretch" src="img/contributions/frame1.svg">
                <img class="fragment r-stretch" src="img/contributions/frame2.svg">
            </div>

            <aside class="notes">
                This is the big picture of all the contributions I've made. For
                now, I don't want to go into detail with them.

                I do want that the contributions can be divided into two categories.
                The first one deals with the challenges of planning in the real
                world when a model is given.

                The second one revolves around acquiring those models from
                demonstration.
            </aside>



            <!--<div class="r-hstack" style="justify-content:space-evenly;">-->
                <!--<figure style="width:500px;" class="fragment">-->
                    <!--<img class="" src="img/contributions/first_part.png">-->
                    <!--<figcaption>New planning algorithms</figcaption>-->
                <!--</figure>-->

                <!--<figure style="width:500px;" class="fragment">-->
                    <!--<img class="" src="img/contributions/second_part.png">-->
                    <!--<figcaption>Learning algorithms</figcaption>-->
                <!--</figure>-->
            <!--</div>-->

        </section>

        <!--<section>-->
            <!--<div class="r-stack">-->
                <!--<img class="r-stretch" src="img/contributions/frame1.svg">-->
                <!--<img class="fragment r-stretch" src="img/contributions/frame2.svg">-->
            <!--</div>-->
        <!--</section>-->

        <section>
            <h2 class="numbered-section">Planning and Execution</h2>
            <div class="r-stack">
                <img class="r-stretch" src="img/contributions/splash1.svg">
                <figure class="fragment" style="padding:10px;position:fixed;left:690px;top:120px;background-color:white;border: black dashed">
                    <img style="height:500px;" src="img/contributions/projects1.png">
                    <figcaption>Manipulation use cases</figcaption>
                </figure>
            </div>

            <aside class="notes">

                So let's start with this first set of contributions. At this
                point, I'd like to mention that these contributions have been
                exemplified with manipulation tasks involving one or more
                robot arms. In particular, one of the use cases comes from
                IMAGINE, an European H2020 research programme whose scientific
                goal was to enable robots to understand their surroundings.
                This scientific vision was channeled through the particular use
                case of electromechanical device disassembly.


            </aside>
        </section>

        <section>
            <h3 class="numbered-section">Dual-arm Symbolic-motion Planning</h3>

            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash11.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img width="200" src="img/dual-arm-planning/game-introduction.gif">
                      <figcaption>Complex manipulation...</figcaption>
                    </figure>

                    <figure style="">
                      <img width="200" src="img/dual-arm-planning/picker-and-catcher.png">
                      <figcaption>... with dual-arm robot set-ups</figcaption>
                    </figure>
                </div>

                <aside class="notes">
                    On to the first contribution. In this contribution, we wanted
                    dual-arm robots to perform a complex manipulation task, avoiding
                    self collision and dealing with noisy perceptions. We proposed
                    this task, which consists of inserting pieces in a sphere with
                    cavities, as the motivating example. The reason why is that
                    this task has many challenges/opportunities that are representative
                    of the difficulties we often face in robotics.
                </aside>

            </div>


            <div class="reference" style="padding-top: 50px;" >
                <strong>A. Suárez-Hernández</strong>, G. Alenyà, and C. Torras. "Interleaving hierarchical task planning and motion constraint testing for
                dual-arm manipulation." In <strong>IEEE/RSJ IROS 2018</strong>, pp. 4061–4066.
            </div>
        </section>


        <section>
            <h4>Addressed problems</h4>

            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li class="fragment semi-fade-out" data-fragment-index="1">Symbolic-geometric reasoning (<strong>O1</strong>)</li>
                        <li class="fragment" data-fragment-index="1">Partial observability (<strong>O3</strong>)</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                    <figure class="fragment fade-out" data-fragment-index="1">
                      <img style="height:300px;" src="img/dual-arm-planning/example-symbolic.png">
                      <img style="height:300px;" src="img/dual-arm-planning/example-geometric.png">
                    </figure>
                    <img class="fragment" data-fragment-index="1" style="width:375px;" src="img/dual-arm-planning/example-partial-observability.png">
                </div>

                <aside class="notes">
                    The first of these challenges is that we want to avoid self-collision between the robots.
                    But, at the same time we would like to perform the task as quickly as possible, so we would
                    like to avoid solutions that are too conservative like, per example, returning each robot to
                    a home or neutral position each time an action is performed.

                    The second one is that the scene is mounted on the ceiling,
                    so it's quite difficult to identify correctly the pieces
                    that are placed on top of the table.
                </aside>
            </div>

        </section>

        <section>
            <h4>Literature</h4>

            <div class="r-stack">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/dual-arm-planning/literature1.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/dual-arm-planning/literature2.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/dual-arm-planning/literature3.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/dual-arm-planning/literature4.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/dual-arm-planning/literature5.svg">
            </div>

            <aside class="notes">

                What's out there? What's usually done? Well, this is the paper we took inspiration from. In it,
                Lozano-Pérez and Kaelbling propose a hierarchical decomposition of the goal in order to keep
                the planning horizon short, they also quantify uncertainty and plan noise reduction actions.
                However, they do not consider the case of self collision nor the problem of
                misidentificating objects.

                It is worth mentioning that, although the problem of task and motion integration has
                been known for quite some time, it was around the time I worked on this contribution
                that research on this topic surged and became known as TAMP, Task and Motion
                Planning. Reviews like this offer a taxonomy of the available methods.

                There's been also a surge in tree control structures that have
                the capability to react quickly to disturbances, and apply
                appropriate actions. One such example is Behavior Trees.
                Conversely, we use Hierarchical Task Networks, which are quite
                similar in spirit.

                And here's further evidence of this trend towards hierarchical
                control trees. This one is pretty similar to Behavior Trees.

                Finally, I'd like to provide an example of sequential
                strategies. In this case, task planning and motion planning
                were not interleaved, like in our case, and the success of the task
                was entirely depending on a re-planning cycle.

            </aside>
        </section>

        <!--<section>-->
            <!--<h4>Specific contributions</h4>-->

            <!--<div class="r-hstack">-->

                <!--<div style="width:50%;">-->

                    <!--<ul>-->
                        <!--<li class="fragment semi-fade-out" data-fragment-index="1">Encode dual-arm alternatives in HTNs (<strong>O1</strong>)</li>-->
                        <!--<li class="fragment" data-fragment-index="1">Quantify uncertainty (<strong>O3</strong>)</li>-->
                    <!--</ul>-->

                <!--</div>-->

                <!--<div class="r-stack" style="width:50%">-->
                  <!--<img class="fragment fade-out" data-fragment-index="1" style="width:100%;" src="img/dual-arm-planning/htn.png">-->
                  <!--<figure style="vertical-align:bottom;" class="fragment" data-fragment-index="1">-->
                    <!--<img style="width:400px;" src="img/dual-arm-planning/dispel-noise.png">-->
                    <!--<img style="width:400px;" src="img/dual-arm-planning/pushing.gif">-->
                    <!--<figcaption>Information gathering (top), reshaping (bottom)</figcaption>-->
                  <!--</figure>-->

                <!--</div>-->
            <!--</div>-->

        <!--</section>-->

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li class="">Encode dual-arm alternatives in HTNs (<strong>O1</strong>)</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                  <img class="" style="width:100%;" src="img/dual-arm-planning/htn.png">
                </div>
            </div>

        </section>

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div class="r-hstack">

                <div style="width:50%;"></div>

                <img class="r-stretch" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn1.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn2.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn3.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn4.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn5.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn6.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn7.png">
            </div>

        </section>

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li style="opacity:50%;">Encode dual-arm alternatives in HTNs (<strong>O1</strong>)</li>
                        <li >Quantify uncertainty (<strong>O3</strong>)</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                  <img class="" style="width:100%;" src="img/dual-arm-planning/htn.png">
                </div>
            </div>

        </section>

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div class="r-hstack">

                <div style="width:50%;"></div>

                <img class="r-stretch" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn8.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn9.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn10.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn11.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn12.png">
                <img class="r-stretch fragment fade-in-then-out" style="position:absolute;width:100%;" src="img/dual-arm-planning/htn13.png">
                <figure style="vertical-align:bottom;position:absolute;width:70%;background-color:white;border:black dashed; padding:20px;" class="fragment">
                  <img style="height:200px;" src="img/dual-arm-planning/pushing.gif">
                  <img style="height:200px;" src="img/dual-arm-planning/dispel-noise.png">
                  <figcaption>Reshaping (left), information gathering (right)</figcaption>
                </figure>

            </div>

        </section>

        <section>

            <h4>Quantitative experiments</h4>

            <div class="r-hstack" style="justify-content:space-evenly;">
              <figure>
                  <div class="r-stack">
                    <img src="img/dual-arm-planning/results.svg">
                    <img class="fragment" src="img/dual-arm-planning/results1.svg">
                    <img class="fragment fade-in-then-out" src="img/dual-arm-planning/results2.svg">
                    <img class="fragment fade-in-then-out" src="img/dual-arm-planning/results3.svg">
                    <img class="fragment fade-in-then-out" src="img/dual-arm-planning/results4.svg">
                    <img class="fragment fade-in-then-out" src="img/dual-arm-planning/results5.svg">
                    <img class="fragment fade-in-then-out" src="img/dual-arm-planning/results6.svg">
                  </div>
                  <figcaption>Results (simulation)</figcaption>
              </figure>
              <div class="r-vstack">
                <figure class="">
                  <img style="height:240px;" src="img/dual-arm-planning/algorithm-A-scenario-a.gif">
                  <figcaption>Algorithm A in (a)</figcaption>
                </figure>
                <figure class="">
                  <img style="height:240px;" src="img/dual-arm-planning/algorithm-F-scenario-c.gif">
                  <figcaption>Algorithm F in (c)</figcaption>
                </figure>
              </div>
            </div>
        </section>

        <section>
            <h4>Qualitative experiment</h4>
            <video class="r-stretch" controls onloadstart="this.playbackRate = 10;">
                <source data-src="http://www.iri.upc.edu/groups/perception/dual_arm_planning/video/itm_demo_real.mp4" type="video/mp4">
            </video>
        </section>

        <section>
            <h3 class="numbered-section">Planning in Face of Stochastic Outcomes</h3>


            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash12.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img width="200" src="img/handling-uncertain-outcomes/unscrew.gif">
                      <img width="200" src="img/handling-uncertain-outcomes/remove-pcb.gif">
                      <figcaption>Disassembly with uncertainty</figcaption>
                    </figure>

                </div>

            </div>


            <div class="reference" style="padding-top: 50px;" >
                <strong>A. Suárez-Hernández</strong>, C. Torras, and G. Alenyà.
                  "Practical resolution methods for MDPs in robotics exemplified
                  with disassembly planning." In <strong>IEEE RA-L (2019)</strong>, pp. 2282–2288.
            </div>

        </section>

        <section>
            <h4>Addressed problems</h4>

            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li class="fragment semi-fade-out" data-fragment-index="1">Handle uncertain outcomes (<strong>O2</strong>)</li>
                        <li class="fragment" data-fragment-index="1">Handle partial observability (occlusions) (<strong>O3</strong>)</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                    <figure class="fragment fade-out" data-fragment-index="1">
                      <img style="padding-bottom:200px;" src="img/handling-uncertain-outcomes/stochastic-action.png">
                      <img style="height:200px;position:fixed;left:620px;top:257px;" src="img/handling-uncertain-outcomes/successful-action.gif">
                      <img style="height:200px;position:fixed;left:941px;top:257px;" src="img/handling-uncertain-outcomes/unsuccessful-action.gif">
                    </figure>
                    <img class="fragment" data-fragment-index="1" style="height:375px;" src="img/handling-uncertain-outcomes/device-with-hidden-components.png">
                </div>
            </div>

        </section>

        <section>
            <h4>Literature</h4>

            <div class="r-stack">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/handling-uncertain-outcomes/literature1.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/handling-uncertain-outcomes/literature2.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/handling-uncertain-outcomes/literature3.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/handling-uncertain-outcomes/literature4.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/handling-uncertain-outcomes/literature5.svg">
            </div>
        </section>

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div style="width:100%;height:700px;position:absolute">
            <img style="width:500px;" src="img/handling-uncertain-outcomes/architecture.png">
            </div>

            <!--<div class="r-hstack" style="justify-content:space-evenly;">-->
              <!--<figure class="fragment" style="width:50%;vertical-align:bottom;">-->
                <!--<img style="height:400px;" src="img/handling-uncertain-outcomes/architecture.svg">-->
                <!--<figcaption>System architecture</figcaption>-->
              <!--</figure>-->
              <!--<figure style="width:50%;vertical-align:bottom;" class="">-->
                <!--<img class="fragment" src="img/handling-uncertain-outcomes/subtask-selection.png">-->
              <!--</figure>-->
            <!--</div>-->

        </section>

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div style="width:100%;height:700px;position:absolute">
            <img style="height:200px;max-height:none;position:absolute;top:0px;left:0px;" src="img/handling-uncertain-outcomes/architecture.png">
            <div class="fragment" data-id="box" data-fragment-index="1" style="border:solid red;width:120px;height:30px;position:absolute;top:69px;left:44px;"></div>
            <div class="r-stack">
                <img class="fragment fade-in-then-out" style="width:700px;position:absolute;top:50%;left:50%;transform: translate(-50%,-50%);" data-fragment-index="1" src="img/handling-uncertain-outcomes/subtask-selection-simple.svg">
                <img class="fragment" style="width:800px;position:absolute;top:50%;left:50%;transform: translate(-50%,-50%);" data-fragment-index="2" src="img/handling-uncertain-outcomes/subtask-selection.svg">
            </div>
            </div>
        </section>

        <section data-auto-animate>
            <h4>Specific contributions</h4>

            <div style="width:100%;height:700px;position:absolute">
            <img style="height:200px;max-height:none;position:absolute;top:0px;left:0px;" src="img/handling-uncertain-outcomes/architecture.png">
            <div data-id="box" style="border:solid red;width:120px;height:30px;position:absolute;top:129px;left:44px;"></div>
            <img class="" style="width:800px;position:absolute;top:50%;left:50%;transform: translate(-50%,-50%);" data-fragment-index="1" src="img/handling-uncertain-outcomes/determinization.svg">
            </div>
        </section>

        <section>
            <h4>Results</h4>

            <div class="r-stack">
                <img class="fragment fade-out" data-fragment-index="1" src="img/handling-uncertain-outcomes/results.png">

                <div class="r-hstack fragment" data-fragment-index="1">
                    <figure>
                    <img src="img/handling-uncertain-outcomes/results_success.svg">
                    <figcaption>Success ratio</figcaption>
                    </figure>
                    <figure class="fragment">
                    <img src="img/handling-uncertain-outcomes/results_cost.svg">
                    <figcaption>Cost (#actions)</figcaption>
                    </figure>
                </div>
            </div>

        </section>

        <section>

            <h3 class="numbered-section">Leveraging Simulators to Minimize Risk</h3>


            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash13.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img width="300" src="img/leveraging-simulators/lever-failure1.gif">
                      <img width="300" src="img/leveraging-simulators/lever-failure2.gif">
                      <figcaption>How to anticipate failures?</figcaption>
                    </figure>

                </div>

            </div>


            <div class="reference" style="padding-top: 50px;" >
                <strong>A. Suárez-Hernández</strong>, T. Gaugry, J. Segovia-Aguas,
                  A. Bernardin, C. Torras, M. Marchal, and G. Alenyà.
                  "Leveraging Multiple Environments for Learning and Decision Making:
                  a Dismantling Use Case.” In: <strong>IEEE/RSJ IROS 2020</strong>, pp. 6902–6908.
            </div>

        </section>

        <section>
            <h4>Problems addressed</h4>


            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li class="fragment semi-fade-out" data-fragment-index="1">Unknown frequency of outcomes (<strong>O2</strong>)</li>
                        <li class="fragment" data-fragment-index="1">Distinguish among actions? (<strong>O1</strong>)</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                    <figure class="fragment fade-out" data-fragment-index="1">
                        <img style="width:40%;" src="img/leveraging-simulators/exp1.gif">
                        <img style="width:40%;" src="img/leveraging-simulators/exp2.gif">
                        <img style="width:40%;" src="img/leveraging-simulators/exp3.gif">
                    </figure>
                    <figure class="fragment" data-fragment-index="1">
                        <img style="width:75%" src="img/leveraging-simulators/lever-success.gif">
                        <img style="width:75%" src="img/leveraging-simulators/lever-success2.gif">
                    </figure>
                </div>
            </div>


        </section>

        <section>
            <h4>Literature<h4>
            <div class="r-stack">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/leveraging-simulators/literature1.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/leveraging-simulators/literature2.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/leveraging-simulators/literature3.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/leveraging-simulators/literature4.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/leveraging-simulators/literature5.svg">
            </div>
        </section>

        <section>
            <h4>Specific contributions</h4>

            <div class="r-hstack spaced-horizontally">
                <figure style="width:50%" class="fragment">
                    <img src="img/leveraging-simulators/menid.svg">
                    <figcaption>Multiple Environment NID (MENID) rules</figcaption>
                </figure>

                <figure style="width:50%;" class="fragment">
                    <img style="width:50%;" src="img/leveraging-simulators/architecture.png">
                    <img style="position:fixed;width:100px;top:405px;left:776px;" src="img/leveraging-simulators/lever-success-sim.gif">
                    <img style="position:fixed;width:100px;top:405px;left:932px;" src="img/leveraging-simulators/lever-success.gif">
                    <figcaption style="padding-top:100px">System architecture</figcaption>
                </figure>

            </div>

        </section>

        <section>
            <h4>Model resolution</h4>

            <figure>
                <img src="img/leveraging-simulators/simulation-quality.svg">
                <figcaption>Effect of model resolution on time and accuracy</figcaption>
            </figure>
        </section>

        <section>
            <h4>Algorithm visualization (test+target)</h4>

            <video class="r-stretch" controls>
                <source data-src="video/bandits_w_sim.mp4" type="video/mp4">
            </video>

        </section>

        <!--<section>-->
            <!--<h4>Algorithm visualization (only target)</h4>-->

            <!--<video class="r-stretch" controls>-->
                <!--<source data-src="video/bandits_wo_sim.mp4" type="video/mp4">-->
            <!--</video>-->

        <!--</section>-->

        <section data-auto-animate>
            <h4>Results</h4>

            <div data-id="plots" class="r-vstack">
                <figure>
                    <img src="img/leveraging-simulators/results-simulation.png">
                    <figcaption data-id="caption1">Results low-accuracy simulation $ \rightarrow $ high-accuracy simulation</figcaption>
                </figure>
                <figure style="padding-top:10px;">
                    <img src="img/leveraging-simulators/results-robot.png">
                    <figcaption data-id="caption2">Results simulation $ \rightarrow $ real robot</figcaption>
                </figure>
            </div>

            <div class="fragment" data-id="box" style="position:absolute;border:red solid;top:73px;left:30px;width:1115px;height:300px">
            </div>
        </section>

        <section data-auto-animate>
            <h4>Results</h4>

            <div data-id="plots" class="r-vstack">
                <figure>
                    <img src="img/leveraging-simulators/results-simulation.png">
                    <figcaption data-id="caption1">Results low-accuracy simulation $ \rightarrow $ high-accuracy simulation</figcaption>
                </figure>
                <figure style="padding-top:10px;">
                    <img src="img/leveraging-simulators/results-robot.png">
                    <figcaption data-id="caption2">Results simulation $ \rightarrow $ real robot</figcaption>
                </figure>
            </div>

            <div data-id="box" style="position:absolute;border:red solid;top:407px;left:30px;width:1115px;height:300px">
            </div>
        </section>

        <section data-auto-animate>
            <h4>Results</h4>

            <div data-id="plots" class="r-vstack">
                <figure>
                    <img src="img/leveraging-simulators/results-simulation.png">
                    <figcaption data-id="caption1">Results low-accuracy simulation $ \rightarrow $ high-accuracy simulation</figcaption>
                </figure>
                <figure style="padding-top:10px;">
                    <img src="img/leveraging-simulators/results-robot.png">
                    <figcaption data-id="caption2">Results simulation $ \rightarrow $ real robot</figcaption>
                </figure>
            </div>

            <div data-id="box" style="position:absolute;border:red solid;top:73px;left:30px;width:400px;height:630px;">
            </div>
        </section>

        <section data-auto-animate>
            <h4>Results</h4>

            <div data-id="plots" class="r-vstack">
                <figure>
                    <img src="img/leveraging-simulators/results-simulation.png">
                    <figcaption data-id="caption1">Results low-accuracy simulation $ \rightarrow $ high-accuracy simulation</figcaption>
                </figure>
                <figure style="padding-top:10px;">
                    <img src="img/leveraging-simulators/results-robot.png">
                    <figcaption data-id="caption2">Results simulation $ \rightarrow $ real robot</figcaption>
                </figure>
            </div>

            <div data-id="box" style="position:absolute;border:red solid;top:73px;left:406px;width:400px;height:630px;">
            </div>
        </section>

        <section data-auto-animate>
            <h4>Results</h4>

            <div data-id="plots" class="r-vstack">
                <figure>
                    <img src="img/leveraging-simulators/results-simulation.png">
                    <figcaption data-id="caption1">Results low-accuracy simulation $ \rightarrow $ high-accuracy simulation</figcaption>
                </figure>
                <figure style="padding-top:10px;">
                    <img src="img/leveraging-simulators/results-robot.png">
                    <figcaption data-id="caption2">Results simulation $ \rightarrow $ real robot</figcaption>
                </figure>
            </div>

            <div data-id="box" style="position:absolute;border:red solid;top:73px;left:786px;width:400px;height:630px;">
            </div>
        </section>

        <section>
            <h2 class="numbered-section">Learning Planning Operators</h2>

            <div class="r-stack">
                <img class="r-stretch" src="img/contributions/splash2.svg">
                <figure class="fragment" style="padding:10px;position:fixed;left:0px;top:120px;background-color:white;border: black dashed">
                    <img style="height:500px;" src="img/contributions/projects2.png">
                    <figcaption>Intuitive programming of SAR</figcaption>
                </figure>
            </div>


            <!--<img class="r-stretch" src="img/contributions/splash2.svg">-->

        </section>

        <section>
            <h3 class="numbered-section">STRIPS Action Discovery</h3>

            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash24.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img style="width:90%;" src="img/udam/udam-teaser.png">
                      <figcaption>Example STRIPS action for visit-all domain</figcaption>
                    </figure>

                </div>

            </div>

            <div class="reference" style="padding-top: 100px;">
                <strong>A. Suárez-Hernández</strong>, J. Segovia-Aguas, C. Torras, and
                G. Alenyà. “STRIPS action discovery.” In: arXiv preprint arXiv:
                2001.11457 (2020). <strong>Presented in the 1st Workshop on Generalization in
                Planning at the 2020 AAAI conference</strong>.
            </div>
        </section>

        <section>
            <h4>Addressed problems</h4>

            <div class="r-hstack">
                <ul>
                    <li class="fragment semi-fade-out" data-fragment-index="1">Learning STRIPS state traces (<strong>O4</strong>)</li>
                    <li class="fragment" data-fragment-index="1"><strong>Minimal information</strong></li>
                </ul>

                <div class="r-stack">
                    <img class=""src="img/udam/traces1.svg">
                    <img class="fragment" data-fragment-index="1" src="img/udam/traces2.svg">
                    <img class="fragment"src="img/udam/traces3.svg">
                </div> 
            </div>
        </section>

        <section>
            <h4>Literature</h4>

            <div class="r-stack">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/udam/literature1.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/udam/literature2.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/udam/literature3.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/udam/literature4.svg">
            </div>
        </section>

        <section>
            <h4>FAMA/DAM compilation</h4>

            <p>Learn action models for a given configuration (known #actions, #parameters per action)</p>

            <div class="r-hstack spaced-horizontally">
                <figure>
                <img class="" style="height:225px;" src="img/udam/strips.png">
                <figcaption>STRIPS action</figcaption>
                </figure>
                <figure class="fragment">
                <img class="" style="height:225px;" src="img/udam/fama.png">
                <figcaption>Learn via classical planning</figcaption>
                </figure>
            </div>

        </section>

        <section>
            <h4>Specific contributions</h4>

            <figure>
                <div class="r-stack">
                    <img class="" style="width:800px;" src="img/udam/udam1.svg">
                    <img class="fragment" style="width:800px;" src="img/udam/udam2.svg">
                </div>
                <figcaption>Unsupervised Discovery of Action Models</figcaption>
            </figure>
        </section>

        <section>
            <h4>Results</h4>

            <img src="img/udam/results.png">
        </section>

        <section>
            <h3 class="numbered-section">INtuitive PROgramming</h3>

            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash25.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img style="width:60%;" src="img/inpro/aleks.png">
                      <figcaption>A teacher demonstrating a cognitive exercise</figcaption>
                    </figure>

                </div>

            </div>

            <div class="reference" style="padding-top: 100px;">
                A. Andriella, <strong>A. Suárez-Hernández</strong>, J. Segovia-Aguas, 
                C. Torras, and G, Alenya. "Natural teaching of robot-assisted
                rearranging exercises for cognitive training." In <strong>ICSR 2019</strong>, pp. 611–621
            </div>
            <div class="reference" style="padding-top: 10px;">
                <strong>A. Suárez-Hernández</strong>, A. Andriella, A. Taranović,
                J. Segovia-Aguas, C. Torras, and G. Alenyà. "Automatic
                learning of cognitive exercises for socially assistive robotics."
                In <strong>RO-MAN 2021</strong>, pp. 139–146
            </div>
        </section>

        <section>
            <h4>Addressed problems</h4>

            <div class="r-hstack">
                <ul>
                    <li class="fragment" data-fragment-index="1">How can non-expert users extend robot's behavior (<strong>O4</strong>)?</li>
                </ul>

                <figure>
                     <img style="height:300px;" src="img/inpro/games.png">
                     <figcaption>Cognitive exercises set-up</figcaption>
                </figure>

            </div>
 
        </section>

        <section>
            <h4>Literature</h4>

            <div class="r-stack">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/inpro/literature1.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/inpro/literature2.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/inpro/literature3.svg">
                <img class="r-stretch fragment fade-in-then-semi-out" src="img/inpro/literature4.svg">
            </div>
        </section>

        <section>
            <h4>Specific contributions</h4>
            
            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li class="fragment semi-fade-out" data-fragment-index="1"><strong>IN</strong>tuitive <strong>PRO</strong>gramming (INPRO): practical application of action model learning algorithm (INPRO)</li>
                        <li class="fragment" data-fragment-index="1">Feedback strategies to inform teacher</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                    <figure class="fragment" data-fragment-index="1">
                        <img style="width:75%" src="img/inpro/screen.png">
                        <figcaption>INPRO feedback</figcaption>
                    </figure>
                </div>
            </div>

        </section>

        <section>
            <h4>Hypotheses</h4>

            <ul>
                <li><strong>H1</strong>: teachers from the minimum feedback group will require more traces to
                    complete the exercises</li>
                <li><strong>H2</strong>: more teachers in the full feedback group will teach all exercise rules</li>
            </ul>
        </section>

        <section>
            <h4>Results</h4>

            <div class="r-hstack">
              <figure style="width:50%;" class="">
                <img style="height:150px;" src="img/inpro/table.png">
                <figcaption>User study results (tabular)</figcaption>
              </figure>
              <figure class="fragment" style="width:50%;vertical-align:bottom;">
                <img style="height:370px;" src="img/inpro/plot.png">
                <figcaption>Error vs proportion of participants</figcaption>
              </figure>
            </div>
        </section>

        <section>
            <h3 class="numbered-section">Online Action Recognition through Unification</h3>

            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash26.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img style="height:300px;" src="img/oaru/sokoban_animation.gif">
                      <figcaption>Could we learn Sokoban rules from demonstrations?</figcaption>
                    </figure>

                </div>

            </div>


            <div class="reference" style="padding-top: 50px;">
                <strong>A. Suárez-Hernández</strong>, J. Segovia-Aguas, C. Torras, and
                G. Alenyà. "Online Action Recognition." In: <strong>AAAI 2021 Conference</strong>,
                pp. 11981–11989
            </div>
        </section>

        <section>
            <h4>Addressed problems</h4>

            <ul>
                <li class="fragment">Real-time STRIPS action learning</li>
                <li class="fragment">Learning even with Partial Observability</li>
                <li class="fragment">Few-shot performance</li>
            </ul>
        </section>

        <section>
            <h4>Specific contributions</h4>

            <div class="r-hstack">

                <div style="width:50%;">

                    <ul>
                        <li class="fragment semi-fade-out" data-fragment-index="1">New algorithm for merging actions (AU)</li>
                        <li class="fragment" data-fragment-index="1">Online Action through Unification (OARU)</li>
                    </ul>

                </div>

                <div class="r-stack" style="width:50%">
                    <img style="height:600px;" src="img/oaru/teaser.svg">
                </div>
            </div>
        </section>

        <section>


            <video id="itm-video" controls onloadstart="this.playbackRate = 1;">
                <source data-src="video/teaser-oaru.mp4" type="video/mp4">
            </video>

        </section>

        <section>
            <h4>Results (full observability)</h4>

            <div class="r-hstack">
              <figure style="width:50%;" class="">
                <img style="height:300px;" src="img/oaru/results_a.png">
                <figcaption>Statistics</figcaption>
              </figure>
              <figure class="fragment" style="width:50%;vertical-align:bottom;">
                <img style="height:370px;" src="img/oaru/full_obs_updates-crop.svg">
                <figcaption>#Updates vs #steps</figcaption>
              </figure>
            </div>

        </section>

        <section>
            <h4>Results (partial observability)</h4>

            <div class="r-hstack">
              <figure style="width:50%;" class="">
                <img style="height:300px;" src="img/oaru/results_b.png">
                <figcaption>Statistics</figcaption>
              </figure>
              <figure class="fragment" style="width:50%;vertical-align:bottom;">
                <img style="height:370px;" src="img/oaru/partial_obs_updates-crop.svg">
                <figcaption>#Updates vs #steps</figcaption>
              </figure>
            </div>
        </section>

        <section>
            <h3 class="numbered-section">INtuitive PROgramming 2</h3>

            <div class="r-hstack">

                <div style="width:50%">
                    <img src="img/contributions/splash27.svg">
                </div>

                <div style="width:50%;" class="fragment">
                    <figure style="">
                      <img style="height:300px;" src="img/inpro2/teaching-helena.gif">
                      <figcaption>Teaching cognitive exercises to a robot</figcaption>
                    </figure>

                </div>

            </div> 

            <div class="reference" style="padding-top: 100px;">
                A. Suárez-Hernández, A. Andriella, C. Torras,
                and G. Alenyà. "User Interactions and Negative Examples
                to Improve the Learning of Semantic Rules in a Cognitive
                Exercise Scenario." In IROS 2023, pp. 7953–7960.
            </div>
        </section>

        <section>
            <h4>Addressed problems</h4>

            <ul>
                <li class="fragment fade-in-then-semi-out" data-fragment-index="1">Learn more complex exercises</li>
                <li class="fragment" data-fragment-index="2">Until now: robot hasn't been very proactive</li>
                <li class="fragment">Learn goals?</li>
            </ul>
        </section>

        <section>
            <h4>Specific contributions</h4>

            <ul>
                <li class="fragment semi-fade-out" data-fragment-index="1">Adopt OARU in SAR scenario</li>
                <li class="fragment fade-in-then-semi-out" data-fragment-index="1">Improve OARU with negative examples</li>
                <li class="fragment fade-in-then-semi-out">Learn goals</li>
                <li class="fragment fade-in-then-semi-out">Proactive questioning</li>
            </ul>
        </section>

        <section>
            <h4>Execution example</h4>

            <div class="r-stack">
                <img class="r-stretch" src="img/inpro2/method1_frame1.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame2.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame3.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame4.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame5.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame6.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame7.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame8.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame9.svg">
                <img class="r-stretch fragment" src="img/inpro2/method1_frame10.svg">
            </div>

        </section>

        <section>
            <h4>Prompting criterion</h4>

            <div class="r-stack">
                <img class="r-stretch" src="img/inpro2/method2_frame1.svg">
                <img class="r-stretch fragment" src="img/inpro2/method2_frame2.svg">
                <img class="r-stretch fragment" src="img/inpro2/method2_frame3.svg">
                <img class="r-stretch fragment" src="img/inpro2/method2_frame4.svg">
                <img class="r-stretch fragment" src="img/inpro2/method2_frame5.svg">
                <img class="r-stretch fragment" src="img/inpro2/method2_frame6.svg">
                <img class="r-stretch fragment" src="img/inpro2/method2_frame7.svg">
            </div>

        </section>

        <section>
            <h4>Quantitative results</h4>

            <img class="r-stretch" src="img/inpro2/results.svg">
        </section>

        <section>
            <h4>Qualitative results</h4>

            <video class="r-stretch" loop controls>
                <source data-src="video/inpro2.mp4" type="video/mp4">
            </video>
        </section>

        <section data-auto-animate>
            <h2 class="numbered-section">Conclusions</h2>

            <p class="r-frame fragment" style="font-size:75%;" data-fragment-index="1">New Methods for
            <span class="fragment highlight-blue" data-fragment-index="2" data-id="item1">Bridging Symbolic-Geometric Reasoning</span>,
            <span class="fragment highlight-red" data-fragment-index="2" data-id="item2">Addressing Uncertainty</span> and
            <span class="fragment highlight-green" data-fragment-index="2" data-id="item3">Action Learning</span>
            in Task Planning for Robotics</p>

            <!--<p class="fragment" data-fragment-index="2">Key advances:</p>-->
            <!--<ul class="fragment" data-fragment-index="2">-->
                <!--<li class="">Simplification <span class="fragment">$ \rightarrow $</span> <span class="fragment blue-box"></span> <span class="fragment red-box"></span></li>-->
                <!--<li class="">Beyond-symbolic reasoning <span class="fragment">$ \rightarrow $</span> <span class="fragment blue-box"></span> </li>-->
                <!--<li class="">Hands-off learning <span class="fragment">$ \rightarrow $</span> <span class="fragment green-box"></span> </li>-->
            <!--</ul>-->

        </section>

        <section data-auto-animate>
            <h2 class="numbered-section dont-increment">Conclusions</h2>

            <div class="r-hstack spaced-horizontally" style="font-size:75%;">
            <span data-id="item1" style="color:#1b91ff;">Bridging Symbolic-Geometric Reasoning</span>
            <span data-id="item2" style="color:#ff2c2d;">Addressing Uncertainty</span>
            <span data-id="item3" style="color:#17ff2e;">Action Learning</span>
            </div>


            <p class="fragment" data-fragment-index="2">Key advances:</p>
            <ul class="fragment" data-fragment-index="2">
                <li data-id="simplification" class="">Simplification <span class="fragment" data-fragment-index="3">$ \rightarrow $</span> <span class="fragment blue-box" data-fragment-index="3"></span> <span data-fragment-index="3" class="fragment red-box"></span></li>
                <li data-id="beyond" class="">Beyond-symbolic reasoning <span data-fragment-index="4" class="fragment">$ \rightarrow $</span> <span data-fragment-index="4" class="fragment blue-box"></span> </li>
                <li data-id="handsoff" class="">Hands-off learning <span data-fragment-index="5" class="fragment">$ \rightarrow $</span> <span data-fragment-index="5" class="fragment green-box"></span> </li>
            </ul>

        </section>

        <section data-auto-animate>
            <h2 class="numbered-section dont-increment">Conclusions</h2>

            <div class="r-hstack spaced-horizontally" style="font-size:75%;">
            <span data-id="item1" style="color:#1b91ff;">Bridging Symbolic-Geometric Reasoning</span>
            <span data-id="item2" style="color:#ff2c2d;">Addressing Uncertainty</span>
            <span data-id="item3" style="color:#17ff2e;">Action Learning</span>
            </div>


            <p class="">Key advances:</p>
            <ul class="">
                <li data-id="simplification" class="">
                    Simplification <span class="">$ \rightarrow $</span> <span class="blue-box" ></span> <span class="red-box"></span>
                    <ul>
                        <li>Hierarchical representations</li>
                        <li>Determinization</li>
                    </ul>
                </li>
                <li data-id="beyond" class="">Beyond-symbolic reasoning <span class="">$ \rightarrow $</span> <span class="blue-box"></span> </li>
                <li data-id="handsoff" class="">Hands-off learning <span class="">$ \rightarrow $</span> <span class="green-box"></span> </li>
            </ul>

        </section>

        <section data-auto-animate>
            <h2 class="numbered-section dont-increment">Conclusions</h2>

            <div class="r-hstack spaced-horizontally" style="font-size:75%;">
            <span data-id="item1" style="color:#1b91ff;">Bridging Symbolic-Geometric Reasoning</span>
            <span data-id="item2" style="color:#ff2c2d;">Addressing Uncertainty</span>
            <span data-id="item3" style="color:#17ff2e;">Action Learning</span>
            </div>


            <p class="">Key advances:</p>
            <ul class="">
                <li data-id="simplification" class="">
                    Simplification <span class="">$ \rightarrow $</span> <span class="blue-box" ></span> <span class="red-box"></span>
                </li>
                <li data-id="beyond" class="">
                    Beyond-symbolic reasoning <span class="">$ \rightarrow $</span> <span class="blue-box"></span>
                    <ul>
                        <li>Uncertainty checks and collision logic in HTNs</li>
                        <li>Leveraging simulators</li>
                    </ul>
                </li>
                <li data-id="handsoff" class="">
                    Hands-off learning <span class="">$ \rightarrow $</span> <span class="green-box"></span>
                </li>
            </ul>

        </section>

        <section data-auto-animate>
            <h2 class="numbered-section dont-increment">Conclusions</h2>

            <div class="r-hstack spaced-horizontally" style="font-size:75%;">
            <span data-id="item1" style="color:#1b91ff;">Bridging Symbolic-Geometric Reasoning</span>
            <span data-id="item2" style="color:#ff2c2d;">Addressing Uncertainty</span>
            <span data-id="item3" style="color:#17ff2e;">Action Learning</span>
            </div>


            <p class="">Key advances:</p>
            <ul class="">
                <li data-id="simplification" class="">
                    Simplification <span class="">$ \rightarrow $</span> <span class="blue-box" ></span> <span class="red-box"></span>
                </li>
                <li data-id="beyond" class="">
                    Beyond-symbolic reasoning <span class="">$ \rightarrow $</span> <span class="blue-box"></span>
                </li>
                <li data-id="handsoff" class="">
                    Hands-off learning <span class="">$ \rightarrow $</span> <span class="green-box"></span>
                    <ul>
                        <li>Learning without action signatures</li>
                        <li>Practical implementation in SAR</li>
                    </ul>
                </li>
            </ul>

        </section>

        <section>
            <h2 class="numbered-section">Future Work</h2>

            <ul>
                <li class="">Simplification
                    <ul>
                        <li>Further strategies to decompose tasks</li>
                        <li>New determinization algorithms</li>
                    </ul>
                </li>

                <li class="fragment">Beyond symbolic reasoning
                    <ul>
                        <li>Leverage more than two environments</li>
                        <li>Compare interleaved simulation/real execution against transfer learning</li>
                    </ul>
                </li>

                <li class="fragment">Hands-off learning
                    <ul>
                        <li>Improve prompting strategies (INPRO 2)</li>
                        <li>Combine OARU/INPRO2 with learned embeddings</li>
                    </ul>
                </li>


            </ul>

        </section>

        <section>
            <h2 style="padding-top:12px;" class="r-fit-text">New Methods for Bridging Symbolic-Geometric Reasoning, Addressing Uncertainty and Action Learning in Task Planning for Robotics</h2>


            <div class="r-stack">
                <img class="r-stretch" src="img/contributions/frame1.svg">
                <img class="r-stretch" src="img/contributions/frame2.svg">
            </div>
        </section>

      </div>
      <!--<div class="frame bottom"></div>-->
      <div class="frame top"></div>
      <!--<div class="frame left"></div>-->
      <!--<div class="frame right"></div>-->
      <div class="logos">
          <img src="assets/logos/IRI_logo.svg" height="50px"/>
          <img src="assets/logos/UPC_logo.svg" height="50px"/>
      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/dist/reveal.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/notes/notes.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/markdown/markdown.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/math/math.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5.1.0/plugin/zoom/zoom.min.js"></script>

    <!--<script src="reveal.js/dist/reveal.js"></script>-->
    <!--<script src="reveal.js/plugin/notes/notes.js"></script>-->
    <!--<script src="reveal.js/plugin/markdown/markdown.js"></script>-->
    <!--[><script src="reveal.js/plugin/highlight/highlight.js"></script><]-->
    <!--<script src="reveal.js/plugin/math/math.js"></script>-->

    <!-- D3 Graphviz -->
    <!--<script src="https://d3js.org/d3.v5.min.js"></script>-->
    <!--<script src="https://unpkg.com/@hpcc-js/wasm@0.3.11/dist/index.min.js" type="javascript/worker"></script>-->
    <!--<script src="https://unpkg.com/d3-graphviz@3.0.5/build/d3-graphviz.js"></script>-->

    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        autoPlayMedia: true,
        hash: true,
        slideNumber: "c/t",
        margin: 0.08,
        width: 1200,
        controls: true,
        //keyboard: {
        //  84: renderGraph
        //},
        math: {
          mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
          config: 'TeX-AMS_HTML-full',
        },
        // Learn about plugins: https://revealjs.com/plugins/
        //plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath ]
        plugins: [ RevealMarkdown, RevealZoom, RevealNotes, RevealMath ]
      })
      .then( () => {
        var headerNumber = [0,0,0,0,0,0],
            headers = document.querySelectorAll("h1.numbered-section, h2.numbered-section, h3.numbered-section, h4.numbered-section, h5.numbered-section, h6.numbered-section")
        for (var h of headers) {
          var level = Number(h.tagName[1]) - 1;
          if (!h.classList.contains("dont-increment")) {
            ++headerNumber[level];
            for (var inner_level = level+1; inner_level < 6; ++inner_level)
              headerNumber[inner_level] = 0;
          }
          var spanElement = document.createElement("SPAN");
          var spanText = document.createTextNode(headerNumber.slice(1,level+1).join(".")+". ");
          spanElement.classList.add("numeral");
          spanElement.appendChild(spanText);
          h.insertBefore(spanElement, h.firstChild);
        }
      })
    </script>
  </body>
</html>
